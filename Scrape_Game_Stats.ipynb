{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 193 of the file /anaconda3/lib/python3.6/runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP})\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP, \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 193 of the file /anaconda3/lib/python3.6/runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP})\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP, \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    }
   ],
   "source": [
    "# Scrape data from website\n",
    "7909\n",
    "base_url = \"http://finalsiren.com/MatchDetails.asp?GameID=\"\n",
    "\n",
    "years = list(map(str,range(1965,2019)))\n",
    "\n",
    "player_data = []\n",
    "\n",
    "def createURL(year):\n",
    "    return base_url + year + suffix\n",
    "\n",
    "for year in years:\n",
    "    # create http request for each page of player data\n",
    "    url = createURL(year)\n",
    "    res  = requests.get(url)\n",
    "    data = res.text\n",
    "    soup = BeautifulSoup(data)\n",
    "    year_data = []\n",
    "    \n",
    "    # Parse data from html\n",
    "    teams = soup.select('.sortable')\n",
    "    for team in teams:\n",
    "        rows = team('tr')\n",
    "        headers = rows[0:2] + rows[len(rows) -1: len(rows)]\n",
    "        players = rows[2:len(rows) -1]\n",
    "        team_data = []\n",
    "        for player in players:\n",
    "            td_list = player('td')\n",
    "            player = []\n",
    "            \n",
    "            # Store data in nested lists\n",
    "            for td in td_list:\n",
    "                player.append(td.text)\n",
    "            team_data.append(player)\n",
    "        year_data.append(team_data)\n",
    "    player_data.append(year_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 193 of the file /anaconda3/lib/python3.6/runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP})\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP, \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    }
   ],
   "source": [
    "# Get the headers for the csv's\n",
    "\n",
    "header_url = createURL('2018')\n",
    "res  = requests.get(header_url)\n",
    "data = res.text\n",
    "soup = BeautifulSoup(data)\n",
    "headers = []\n",
    "\n",
    "team = soup.select('.sortable')[-1]\n",
    "header_row = team('tr')[1]\n",
    "\n",
    "for td in header_row:\n",
    "    headers.append(td.text)\n",
    "    \n",
    "print(headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create csv's and write the player data to the files\n",
    "\n",
    "for i in range(len(player_data)):\n",
    "    with open('afl_players_{}.csv'.format(years[i]), 'w', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile, delimiter=' ')\n",
    "        writer.writerow(headers)\n",
    "        for team in player_data[i]:\n",
    "            for player in team:\n",
    "                writer.writerow(player)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
